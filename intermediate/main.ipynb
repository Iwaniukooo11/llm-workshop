{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d447d5285c5e124",
   "metadata": {},
   "source": [
    "# Experiment example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7682c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:43:50.017984Z",
     "start_time": "2025-05-29T17:43:49.979871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\\intermediate\n",
      "C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\\intermediate\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad18c774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:44:02.615785Z",
     "start_time": "2025-05-29T17:44:02.561232Z"
    }
   },
   "outputs": [],
   "source": [
    "from core.base_model import BaseModel\n",
    "from basic.huggingface_model import HuggingFaceModel\n",
    "from basic.llm_model import LLMModel\n",
    "from intermediate.llm_size_experiment import LLMSizeExperiment\n",
    "from tmp.custom_model import EmotionBERT, EmotionClassifier\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Union\n",
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07523033beea36d",
   "metadata": {},
   "source": [
    "## Temporary, for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209e4bfd4fc245d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(BaseModel):\n",
    "    def __init__(self, model_name: str, device: Union[int, str] = 'cpu', **pipeline_kwargs):\n",
    "        if 'max_length' in pipeline_kwargs:\n",
    "            pipeline_kwargs['max_new_tokens'] = pipeline_kwargs.pop('max_length')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model     = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.model.to('cpu')\n",
    "        self.generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device=0 if device != 'cpu' else -1,\n",
    "            **pipeline_kwargs\n",
    "        )\n",
    "    def train(self, train_loader: DataLoader, x_train, y_train, prompt) -> None:\n",
    "        pass\n",
    "    def predict(self, input_text: str) -> str:\n",
    "#         outputs = self.generator(input_text, num_return_sequences=1)\n",
    "#         return outputs[0][\"generated_text\"][len(input_text):].strip()\n",
    "        return 'joy'\n",
    "    def predict_concept(self, input_text: str) -> str:\n",
    "#         outputs = self.generator(input_text, num_return_sequences=1)\n",
    "#         return outputs[0][\"generated_text\"][len(input_text):].strip()\n",
    "        return \"Sentimantal sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb26a3691c860e5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc4d4a9-122e-4427-b2fa-208863d5153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_simplified_data = load_dataset(\"go_emotions\", \"simplified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6145e3b0-e985-44e7-b14e-ef55dbe379be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/dict.txt\", \"r\") as f:\n",
    "    emotions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def prepare_df(df, emotions):\n",
    "    df[\"label\"] = df[\"labels\"].apply(lambda x: x[0])\n",
    "    df[\"sentiment\"] = df[\"label\"].apply(lambda idx: emotions[idx])\n",
    "    return df[[\"text\", \"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fb33db-5371-4f3b-98fb-d3f089851cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentiment\n",
      "0  My favourite food is anything I didn't have to...    neutral\n",
      "1  Now if he does off himself, everyone will thin...    neutral\n",
      "2                     WHY THE FUCK IS BAYLESS ISOING      anger\n",
      "3                        To make her feel threatened       fear\n",
      "4                             Dirty Southern Wankers  annoyance\n"
     ]
    }
   ],
   "source": [
    "train_df = prepare_df(go_emotions_simplified_data[\"train\"].to_pandas(), emotions)\n",
    "val_df = prepare_df(go_emotions_simplified_data[\"validation\"].to_pandas(), emotions)\n",
    "test_df = prepare_df(go_emotions_simplified_data[\"test\"].to_pandas(), emotions)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a877f961-4917-4782-9b3d-260371973228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"My favourite food is anything I didn't have to cook myself.\", 'Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead', 'WHY THE FUCK IS BAYLESS ISOING', 'To make her feel threatened', 'Dirty Southern Wankers']\n",
      "['neutral', 'neutral', 'anger', 'fear', 'annoyance']\n"
     ]
    }
   ],
   "source": [
    "x_train = train_df['text'].tolist()\n",
    "y_train = train_df['sentiment'].tolist()\n",
    "x_val = val_df['text'].tolist()\n",
    "y_val = val_df['sentiment'].tolist()\n",
    "x_test = test_df['text'].tolist()\n",
    "y_test = test_df['sentiment'].tolist()\n",
    "print(x_train[:5])\n",
    "print(y_train[:5])\n",
    "\n",
    "dataset_name='go_emotions'\n",
    "concept=concept=\"sentiment analysis\"\n",
    "concept_keywords=concept_keywords=[\"sentiment\", \"emotion\"]\n",
    "\n",
    "# llm_models={} TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aaec4c5e17a1940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Temporary for testing\n",
    "x_train = x_train[:10]\n",
    "y_train = y_train[:10]\n",
    "x_val = x_train\n",
    "y_val = y_train\n",
    "x_test = x_train\n",
    "y_test = y_train\n",
    "dataset_name='go_emotions'\n",
    "concept=concept=\"sentiment analysis\"\n",
    "concept_keywords=concept_keywords=[\"sentiment\", \"emotion\"]\n",
    "\n",
    "llm_models={\n",
    "        \"gpt2-124M\": LLM(\"gpt2\", max_length=5, temperature=1.0),\n",
    "        \"gpt2-345M\": LLM(\"gpt2-medium\", max_length=5, temperature=1.0)\n",
    "    }\n",
    "# llm_models={\n",
    "#         \"Phi-3-mini-4k-instruct\": LLMModel(model_name=\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffb11217-55a2-4ade-b814-0a153426be92",
   "metadata": {},
   "outputs": [
    {
     "ename": "PackageNotFoundError",
     "evalue": "No package metadata was found for bitsandbytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:563\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdiscover(name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Testing LLM\u001b[39;00m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m LLMModel(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-mini-4k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m a\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat a depressing day!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\GitHubRepositories\\llm-workshop\\basic\\llm_model.py:67\u001b[0m, in \u001b[0;36mLLMModel.predict\u001b[1;34m(self, input_text)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loaded:\n\u001b[1;32m---> 67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_llm_emotion_prediction(input_text, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotion_list)\n",
      "File \u001b[1;32m~\\Desktop\\GitHubRepositories\\llm-workshop\\basic\\llm_model.py:44\u001b[0m, in \u001b[0;36mLLMModel.load_model\u001b[1;34m(self, force)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loaded \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_llm_model()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\GitHubRepositories\\llm-workshop\\basic\\llm_model.py:48\u001b[0m, in \u001b[0;36mLLMModel._load_llm_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_llm_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 48\u001b[0m     quantization_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[0;32m     49\u001b[0m         load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m         bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m     51\u001b[0m         bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m         bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m     )\n\u001b[0;32m     55\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name)\n\u001b[0;32m     56\u001b[0m     model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m     58\u001b[0m         torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;66;03m# device_map=\"auto\",\u001b[39;00m\n\u001b[0;32m     60\u001b[0m         quantization_config\u001b[38;5;241m=\u001b[39mquantization_config,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\quantization_config.py:508\u001b[0m, in \u001b[0;36mBitsAndBytesConfig.__init__\u001b[1;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    506\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnused kwargs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. These kwargs are not used in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 508\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_init()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\utils\\quantization_config.py:566\u001b[0m, in \u001b[0;36mBitsAndBytesConfig.post_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbnb_4bit_use_double_quant, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbnb_4bit_use_double_quant must be a boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_in_4bit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(importlib\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mversion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbitsandbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.39.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m ):\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4 bit quantization requires bitsandbytes>=0.39.0 - please upgrade your bitsandbytes version\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:1008\u001b[0m, in \u001b[0;36mversion\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m(distribution_name):\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the version string for the named package.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \n\u001b[0;32m   1004\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package to query.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;124;03m    :return: The version string for the package as defined in the package's\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        \"Version\" metadata key.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1008\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m distribution(distribution_name)\u001b[38;5;241m.\u001b[39mversion\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:981\u001b[0m, in \u001b[0;36mdistribution\u001b[1;34m(distribution_name)\u001b[0m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution\u001b[39m(distribution_name):\n\u001b[0;32m    976\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the ``Distribution`` instance for the named package.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m \n\u001b[0;32m    978\u001b[0m \u001b[38;5;124;03m    :param distribution_name: The name of the distribution package as a string.\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;124;03m    :return: A ``Distribution`` instance (or subclass thereof).\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Distribution\u001b[38;5;241m.\u001b[39mfrom_name(distribution_name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\importlib\\metadata\\__init__.py:565\u001b[0m, in \u001b[0;36mDistribution.from_name\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdiscover(name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PackageNotFoundError(name)\n",
      "\u001b[1;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes"
     ]
    }
   ],
   "source": [
    "# Testing LLM\n",
    "a = LLMModel(model_name=\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "a.predict('What a depressing day!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c521c4",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8e0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = LLMSizeExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b18fa75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.DataFrame()\n",
    "prediction_statistics = pd.DataFrame()\n",
    "data_statistics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4a867",
   "metadata": {},
   "source": [
    "### EmotionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ec4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_classifier = EmotionClassifier(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a005bff4192a76cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels setup: 8 unique labels found: ['admiration', 'anger', 'annoyance', 'desire', 'fear', 'gratitude', 'neutral', 'surprise']\n",
      "Epoch 1/2g batch 5/5\n",
      "  Train Loss: 2.2753\n",
      "  Val Accuracy: 0.4000\n",
      "  Val F1 Macro: 0.1875\n",
      "  Val ROC AUC (Macro OVR): 0.8929\n",
      "  New best model saved with F1 Macro: 0.1875\n",
      "Epoch 2/2g batch 5/5\n",
      "  Train Loss: 1.7603\n",
      "  Val Accuracy: 0.8000\n",
      "  Val F1 Macro: 0.7188\n",
      "  Val ROC AUC (Macro OVR): 1.0000\n",
      "  New best model saved with F1 Macro: 0.7188\n",
      "Training finished. Loading best model state.\n",
      "Running experiment for LLM: gpt2-124M\n",
      "Running experiment for LLM: gpt2-345M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "model_statistics_tmp, prediction_statistics_tmp, data_statistics_tmp = experiment.run(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    dataset_name=dataset_name,\n",
    "    concept=concept,\n",
    "    concept_keywords=concept_keywords,\n",
    "    \n",
    "    classifier_name=\"custom_model\",\n",
    "    classifier=custom_classifier,\n",
    "    train_classifier=True,\n",
    "    classifier_train_arguments = {\"epochs\": 2, \"batch_size\": 2},\n",
    "    \n",
    "    llm_models=llm_models,\n",
    "    \n",
    "    prompt_header_llm_concept    = \"In 2 words guess, what task is the model doing:\\n\",\n",
    "    prompt_content_llm_concept   = \"{x_test} -> {y_test}\\n\",\n",
    "    prompt_tail_llm_concept      = \"What is this task?\",\n",
    "    \n",
    "    prompt_header_llm_train    = \"You are a classificator\\n\",\n",
    "    prompt_content_llm_train   = \"{x_train} -> {y_train}\\n\",\n",
    "    prompt_tail_llm_train      = \"Learn based on this.\",\n",
    "    \n",
    "    prompt_llm_simulation= \"{x_test}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8929c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.concat([model_statistics, model_statistics_tmp], ignore_index=True)\n",
    "prediction_statistics = pd.concat([prediction_statistics, prediction_statistics_tmp], ignore_index=True)\n",
    "data_statistics = pd.concat([data_statistics, data_statistics_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28a13b",
   "metadata": {},
   "source": [
    "### roberta-base-go_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe98494e-186c-41a8-8e1b-270a26c76f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGF = HuggingFaceModel(model_name=\"SamLowe/roberta-base-go_emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0deeee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for LLM: gpt2-124M\n",
      "Running experiment for LLM: gpt2-345M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "model_statistics_tmp, prediction_statistics_tmp, data_statistics_tmp = experiment.run(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    dataset_name=dataset_name,\n",
    "    concept=concept,\n",
    "    concept_keywords=concept_keywords,\n",
    "    \n",
    "    classifier_name=\"roberta-base-go_emotions\",\n",
    "    classifier=HGF,\n",
    "    train_classifier=False,\n",
    "    classifier_train_arguments = {},\n",
    "    \n",
    "    llm_models=llm_models,\n",
    "    \n",
    "    prompt_header_llm_concept    = \"In 2 words guess, what task is the model doing:\\n\",\n",
    "    prompt_content_llm_concept   = \"{x_test} -> {y_test}\\n\",\n",
    "    prompt_tail_llm_concept      = \"What is this task?\",\n",
    "    \n",
    "    prompt_header_llm_train    = \"You are a classificator\\n\",\n",
    "    prompt_content_llm_train   = \"{x_train} -> {y_train}\\n\",\n",
    "    prompt_tail_llm_train      = \"Learn based on this.\",\n",
    "    \n",
    "    prompt_llm_simulation= \"{x_test}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a7fe11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.concat([model_statistics, model_statistics_tmp], ignore_index=True)\n",
    "prediction_statistics = pd.concat([prediction_statistics, prediction_statistics_tmp], ignore_index=True)\n",
    "data_statistics = pd.concat([data_statistics, data_statistics_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb8d72035ef92a",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99a45b2f9c0ffa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>llm</th>\n",
       "      <th>classifier_accuracy</th>\n",
       "      <th>classifier_precision</th>\n",
       "      <th>classifier_recall</th>\n",
       "      <th>classifier_f1</th>\n",
       "      <th>classifier_balanced_accuracy</th>\n",
       "      <th>classifier_cohen_kappa</th>\n",
       "      <th>classifier_mcc</th>\n",
       "      <th>llm_concept_accuracy</th>\n",
       "      <th>llm_simulation_accuracy</th>\n",
       "      <th>llm_simulation_precision</th>\n",
       "      <th>llm_simulation_recall</th>\n",
       "      <th>llm_simulation_f1</th>\n",
       "      <th>llm_simulation_balanced_accuracy</th>\n",
       "      <th>llm_simulation_cohen_kappa</th>\n",
       "      <th>llm_simulation_mcc</th>\n",
       "      <th>llm_direct_prediction_accuracy</th>\n",
       "      <th>llm_direct_precision</th>\n",
       "      <th>llm_direct_recall</th>\n",
       "      <th>llm_direct_f1</th>\n",
       "      <th>llm_direct_balanced_accuracy</th>\n",
       "      <th>llm_direct_cohen_kappa</th>\n",
       "      <th>llm_direct_mcc</th>\n",
       "      <th>prompt_header_llm_concept</th>\n",
       "      <th>prompt_content_llm_concept</th>\n",
       "      <th>prompt_tail_llm_concept</th>\n",
       "      <th>prompt_header_llm_train</th>\n",
       "      <th>prompt_content_llm_train</th>\n",
       "      <th>prompt_tail_llm_train</th>\n",
       "      <th>prompt_llm_simulation</th>\n",
       "      <th>llm_predicted_concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.782461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Sentimantal sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.782461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Sentimantal sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.470899</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>0.538173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Sentimantal sentiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.470899</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>0.538173</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Sentimantal sentiment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name                classifier        llm  \\\n",
       "0       1  go_emotions              custom_model  gpt2-124M   \n",
       "1       1  go_emotions              custom_model  gpt2-345M   \n",
       "2       2  go_emotions  roberta-base-go_emotions  gpt2-124M   \n",
       "3       2  go_emotions  roberta-base-go_emotions  gpt2-345M   \n",
       "\n",
       "   classifier_accuracy  classifier_precision  classifier_recall  \\\n",
       "0                  0.8              0.700000           0.750000   \n",
       "1                  0.8              0.700000           0.750000   \n",
       "2                  0.6              0.444444           0.518519   \n",
       "3                  0.6              0.444444           0.518519   \n",
       "\n",
       "   classifier_f1  classifier_balanced_accuracy  classifier_cohen_kappa  \\\n",
       "0       0.718750                      0.750000                0.750000   \n",
       "1       0.718750                      0.750000                0.750000   \n",
       "2       0.470899                      0.583333                0.518072   \n",
       "3       0.470899                      0.583333                0.518072   \n",
       "\n",
       "   classifier_mcc  llm_concept_accuracy  llm_simulation_accuracy  \\\n",
       "0        0.782461                   1.0                      0.0   \n",
       "1        0.782461                   1.0                      0.0   \n",
       "2        0.538173                   1.0                      0.0   \n",
       "3        0.538173                   1.0                      0.0   \n",
       "\n",
       "   llm_simulation_precision  llm_simulation_recall  llm_simulation_f1  \\\n",
       "0                       0.0                    0.0                0.0   \n",
       "1                       0.0                    0.0                0.0   \n",
       "2                       0.0                    0.0                0.0   \n",
       "3                       0.0                    0.0                0.0   \n",
       "\n",
       "   llm_simulation_balanced_accuracy  llm_simulation_cohen_kappa  \\\n",
       "0                               0.0                         0.0   \n",
       "1                               0.0                         0.0   \n",
       "2                               0.0                         0.0   \n",
       "3                               0.0                         0.0   \n",
       "\n",
       "   llm_simulation_mcc  llm_direct_prediction_accuracy  llm_direct_precision  \\\n",
       "0                 0.0                             0.0                   0.0   \n",
       "1                 0.0                             0.0                   0.0   \n",
       "2                 0.0                             0.0                   0.0   \n",
       "3                 0.0                             0.0                   0.0   \n",
       "\n",
       "   llm_direct_recall  llm_direct_f1  llm_direct_balanced_accuracy  \\\n",
       "0                0.0            0.0                           0.0   \n",
       "1                0.0            0.0                           0.0   \n",
       "2                0.0            0.0                           0.0   \n",
       "3                0.0            0.0                           0.0   \n",
       "\n",
       "   llm_direct_cohen_kappa  llm_direct_mcc  \\\n",
       "0                     0.0             0.0   \n",
       "1                     0.0             0.0   \n",
       "2                     0.0             0.0   \n",
       "3                     0.0             0.0   \n",
       "\n",
       "                           prompt_header_llm_concept  \\\n",
       "0  In 2 words guess, what task is the model doing:\\n   \n",
       "1  In 2 words guess, what task is the model doing:\\n   \n",
       "2  In 2 words guess, what task is the model doing:\\n   \n",
       "3  In 2 words guess, what task is the model doing:\\n   \n",
       "\n",
       "  prompt_content_llm_concept prompt_tail_llm_concept  \\\n",
       "0     {x_test} -> {y_test}\\n      What is this task?   \n",
       "1     {x_test} -> {y_test}\\n      What is this task?   \n",
       "2     {x_test} -> {y_test}\\n      What is this task?   \n",
       "3     {x_test} -> {y_test}\\n      What is this task?   \n",
       "\n",
       "     prompt_header_llm_train  prompt_content_llm_train prompt_tail_llm_train  \\\n",
       "0  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "1  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "2  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "3  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "\n",
       "  prompt_llm_simulation  llm_predicted_concept  \n",
       "0              {x_test}  Sentimantal sentiment  \n",
       "1              {x_test}  Sentimantal sentiment  \n",
       "2              {x_test}  Sentimantal sentiment  \n",
       "3              {x_test}  Sentimantal sentiment  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61c30b2fd30583d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>llm_name</th>\n",
       "      <th>x_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>classifier_predicted_label</th>\n",
       "      <th>classifier_predicted_label_confidence</th>\n",
       "      <th>llm_simulation_predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.253798</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.338002</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>anger</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.188880</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.177935</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>annoyance</td>\n",
       "      <td>annoyance</td>\n",
       "      <td>0.182116</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name classifier_name   llm_name  \\\n",
       "0       1  go_emotions    custom_model  gpt2-124M   \n",
       "1       1  go_emotions    custom_model  gpt2-124M   \n",
       "2       1  go_emotions    custom_model  gpt2-124M   \n",
       "3       1  go_emotions    custom_model  gpt2-124M   \n",
       "4       1  go_emotions    custom_model  gpt2-124M   \n",
       "\n",
       "                                              x_test     y_test  \\\n",
       "0  My favourite food is anything I didn't have to...    neutral   \n",
       "1  Now if he does off himself, everyone will thin...    neutral   \n",
       "2                     WHY THE FUCK IS BAYLESS ISOING      anger   \n",
       "3                        To make her feel threatened       fear   \n",
       "4                             Dirty Southern Wankers  annoyance   \n",
       "\n",
       "  classifier_predicted_label  classifier_predicted_label_confidence  \\\n",
       "0                    neutral                               0.253798   \n",
       "1                    neutral                               0.338002   \n",
       "2                    neutral                               0.188880   \n",
       "3                    neutral                               0.177935   \n",
       "4                  annoyance                               0.182116   \n",
       "\n",
       "  llm_simulation_predicted_label  \n",
       "0                            joy  \n",
       "1                            joy  \n",
       "2                            joy  \n",
       "3                            joy  \n",
       "4                            joy  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d99a12878273ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>label_counts</th>\n",
       "      <th>label_proportions</th>\n",
       "      <th>avg_text_length</th>\n",
       "      <th>avg_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>train</td>\n",
       "      <td>10</td>\n",
       "      <td>{'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...</td>\n",
       "      <td>{'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...</td>\n",
       "      <td>66.1</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>val</td>\n",
       "      <td>10</td>\n",
       "      <td>{'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...</td>\n",
       "      <td>{'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...</td>\n",
       "      <td>66.1</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "      <td>{'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...</td>\n",
       "      <td>{'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...</td>\n",
       "      <td>66.1</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>train</td>\n",
       "      <td>10</td>\n",
       "      <td>{'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...</td>\n",
       "      <td>{'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...</td>\n",
       "      <td>66.1</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>val</td>\n",
       "      <td>10</td>\n",
       "      <td>{'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...</td>\n",
       "      <td>{'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...</td>\n",
       "      <td>66.1</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name           classifier_name partition  num_samples  \\\n",
       "0       1  go_emotions              custom_model     train           10   \n",
       "1       1  go_emotions              custom_model       val           10   \n",
       "2       1  go_emotions              custom_model      test           10   \n",
       "3       2  go_emotions  roberta-base-go_emotions     train           10   \n",
       "4       2  go_emotions  roberta-base-go_emotions       val           10   \n",
       "\n",
       "                                        label_counts  \\\n",
       "0  {'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...   \n",
       "1  {'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...   \n",
       "2  {'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...   \n",
       "3  {'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...   \n",
       "4  {'neutral': 3, 'anger': 1, 'fear': 1, 'annoyan...   \n",
       "\n",
       "                                   label_proportions  avg_text_length  \\\n",
       "0  {'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...             66.1   \n",
       "1  {'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...             66.1   \n",
       "2  {'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...             66.1   \n",
       "3  {'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...             66.1   \n",
       "4  {'neutral': 0.3, 'anger': 0.1, 'fear': 0.1, 'a...             66.1   \n",
       "\n",
       "   avg_word_count  \n",
       "0            12.5  \n",
       "1            12.5  \n",
       "2            12.5  \n",
       "3            12.5  \n",
       "4            12.5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2fcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345e7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
