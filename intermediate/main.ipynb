{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d447d5285c5e124",
   "metadata": {},
   "source": [
    "# Experiment testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7682c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\\intermediate\n",
      "C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\\intermediate\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad18c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_size_experiment import LLMSizeExperiment\n",
    "from core.base_model import BaseModel\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07523033beea36d",
   "metadata": {},
   "source": [
    "## Temporary, for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209e4bfd4fc245d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuggingFaceModel(BaseModel):\n",
    "    def __init__(self, model_name: str = \"distilbert-base-uncased\"):\n",
    "        self.model = pipeline(\"text-classification\", model=model_name)\n",
    "    def predict(self, input_text: str) -> str:\n",
    "        print('predict HF')\n",
    "        print(self.model(input_text))\n",
    "        return self.model(input_text)[0][\"label\"]\n",
    "    def train(self, train_loader: DataLoader) -> None:\n",
    "        pass\n",
    "\n",
    "class LLM(BaseModel):\n",
    "    def __init__(self, model_name: str, device: Union[int, str] = 'cpu', **pipeline_kwargs):\n",
    "        if 'max_length' in pipeline_kwargs:\n",
    "            pipeline_kwargs['max_new_tokens'] = pipeline_kwargs.pop('max_length')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model     = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.model.to('cpu')\n",
    "        self.generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device=0 if device != 'cpu' else -1,\n",
    "            **pipeline_kwargs\n",
    "        )\n",
    "    def train(self, train_loader: DataLoader, x_train, y_train, prompt) -> None:\n",
    "        print('Training...')\n",
    "    def predict(self, input_text: str) -> str:\n",
    "        outputs = self.generator(input_text, num_return_sequences=1)\n",
    "        print('Predicting sentiment:')\n",
    "        print('Prompt:', input_text)\n",
    "        print('Output:', outputs)\n",
    "        return random.choice(['POSITIVE', 'NEGATIVE'])\n",
    "#         return outputs[0][\"generated_text\"][len(input_text):].strip()\n",
    "    def predict_concept(self, input_text: str) -> str:\n",
    "        outputs = self.generator(input_text, num_return_sequences=1)\n",
    "        print('Predicting concept:')\n",
    "        print('Prompt:', input_text)\n",
    "        print('Output:', outputs)\n",
    "        return random.choice(['Sentimeng guessing', 'Somethin different'])\n",
    "#         return outputs[0][\"generated_text\"][len(input_text):].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb26a3691c860e5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aaec4c5e17a1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"text\": [\n",
    "        \"I absolutely loved this movie, it was fantastic!\",\n",
    "        \"Worst experience ever. I hated every second.\",\n",
    "        \"The plot was not intriguing and the characters were flat.\",\n",
    "        \"Fantastic performance by the lead actor!\",\n",
    "        \"I wouldn't recommend this to anyone.\",\n",
    "        \"It was not an okay film, boring.\",\n",
    "        \"What a masterpiece! Truly a work of art.\",\n",
    "        \"It bored me to tears, very dull.\",\n",
    "    ],\n",
    "    \"label\": [\n",
    "        \"POSITIVE\",\n",
    "        \"NEGATIVE\",\n",
    "        \"NEGATIVE\",\n",
    "        \"POSITIVE\",\n",
    "        \"NEGATIVE\",\n",
    "        \"NEGATIVE\",\n",
    "        \"POSITIVE\",\n",
    "        \"NEGATIVE\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c521c4",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d87b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = 4\n",
    "x_train=data[\"text\"][:shots]\n",
    "y_train=data[\"label\"][:shots]\n",
    "x_test=data[\"text\"][shots:]\n",
    "y_test=data[\"label\"][shots:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9af0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.DataFrame()\n",
    "prediction_statistics = pd.DataFrame()\n",
    "data_statistics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8e0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = LLMSizeExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a005bff4192a76cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sebastian\\anaconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict HF\n",
      "[{'label': 'POSITIVE', 'score': 0.6439165472984314}]\n",
      "predict HF\n",
      "[{'label': 'NEGATIVE', 'score': 0.99978107213974}]\n",
      "predict HF\n",
      "[{'label': 'POSITIVE', 'score': 0.9998670816421509}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict HF\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997370839118958}]\n",
      "Running experiment for LLM: gpt2-124M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting concept:\n",
      "Prompt: In 2 words guess, what task is the model doing:\n",
      "I wouldn't recommend this to anyone. -> NEGATIVE\n",
      "It was not an okay film, boring. -> NEGATIVE\n",
      "What a masterpiece! Truly a work of art. -> POSITIVE\n",
      "It bored me to tears, very dull. -> NEGATIVE\n",
      "What is this task?\n",
      "Output: [{'generated_text': \"In 2 words guess, what task is the model doing:\\nI wouldn't recommend this to anyone. -> NEGATIVE\\nIt was not an okay film, boring. -> NEGATIVE\\nWhat a masterpiece! Truly a work of art. -> POSITIVE\\nIt bored me to tears, very dull. -> NEGATIVE\\nWhat is this task? It's really boring!\"}]\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: I wouldn't recommend this to anyone.\n",
      "Output: [{'generated_text': \"I wouldn't recommend this to anyone. All I'm saying is\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: It was not an okay film, boring.\n",
      "Output: [{'generated_text': 'It was not an okay film, boring. A lot of folks thought'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: What a masterpiece! Truly a work of art.\n",
      "Output: [{'generated_text': 'What a masterpiece! Truly a work of art.\\n\\nThank you,'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: It bored me to tears, very dull.\n",
      "Output: [{'generated_text': 'It bored me to tears, very dull.\\n\\n\"It\\'s'}]\n",
      "Running experiment for LLM: gpt2-345M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting concept:\n",
      "Prompt: In 2 words guess, what task is the model doing:\n",
      "I wouldn't recommend this to anyone. -> NEGATIVE\n",
      "It was not an okay film, boring. -> NEGATIVE\n",
      "What a masterpiece! Truly a work of art. -> POSITIVE\n",
      "It bored me to tears, very dull. -> NEGATIVE\n",
      "What is this task?\n",
      "Output: [{'generated_text': \"In 2 words guess, what task is the model doing:\\nI wouldn't recommend this to anyone. -> NEGATIVE\\nIt was not an okay film, boring. -> NEGATIVE\\nWhat a masterpiece! Truly a work of art. -> POSITIVE\\nIt bored me to tears, very dull. -> NEGATIVE\\nWhat is this task? - the most boring thing\"}]\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: I wouldn't recommend this to anyone.\n",
      "Output: [{'generated_text': \"I wouldn't recommend this to anyone. There's a lot of\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: It was not an okay film, boring.\n",
      "Output: [{'generated_text': 'It was not an okay film, boring. I hated the film so'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: What a masterpiece! Truly a work of art.\n",
      "Output: [{'generated_text': 'What a masterpiece! Truly a work of art. Truly, truly a masterpiece'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: It bored me to tears, very dull.\n",
      "Output: [{'generated_text': \"It bored me to tears, very dull. I couldn't understand any\"}]\n",
      "Running experiment for LLM: gpt2-774M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting concept:\n",
      "Prompt: In 2 words guess, what task is the model doing:\n",
      "I wouldn't recommend this to anyone. -> NEGATIVE\n",
      "It was not an okay film, boring. -> NEGATIVE\n",
      "What a masterpiece! Truly a work of art. -> POSITIVE\n",
      "It bored me to tears, very dull. -> NEGATIVE\n",
      "What is this task?\n",
      "Output: [{'generated_text': \"In 2 words guess, what task is the model doing:\\nI wouldn't recommend this to anyone. -> NEGATIVE\\nIt was not an okay film, boring. -> NEGATIVE\\nWhat a masterpiece! Truly a work of art. -> POSITIVE\\nIt bored me to tears, very dull. -> NEGATIVE\\nWhat is this task? -> NEGATIVE\\n\"}]\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: I wouldn't recommend this to anyone.\n",
      "Output: [{'generated_text': \"I wouldn't recommend this to anyone. I had one of these\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: It was not an okay film, boring.\n",
      "Output: [{'generated_text': \"It was not an okay film, boring. This is like, '\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: What a masterpiece! Truly a work of art.\n",
      "Output: [{'generated_text': 'What a masterpiece! Truly a work of art. Can anyone tell me what'}]\n",
      "Predicting sentiment:\n",
      "Prompt: It bored me to tears, very dull.\n",
      "Output: [{'generated_text': 'It bored me to tears, very dull.\\n\\nHe was a'}]\n"
     ]
    }
   ],
   "source": [
    "model_statistics_tmp, prediction_statistics_tmp, data_statistics_tmp = experiment.run(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    dataset_name='test_dataset',\n",
    "    concept=\"sentiment analysis\",\n",
    "    concept_keywords=[\"sentiment\", \"emotion\"],\n",
    "    \n",
    "    classifier_name=\"distilbert-sst2\",\n",
    "    classifier=HuggingFaceModel(\"distilbert-base-uncased-finetuned-sst-2-english\"),\n",
    "    \n",
    "    llm_models={\n",
    "        \"gpt2-124M\": LLM(\"gpt2\", max_length=5, temperature=1.0),\n",
    "        \"gpt2-345M\": LLM(\"gpt2-medium\", max_length=5, temperature=1.0),\n",
    "        \"gpt2-774M\": LLM(\"gpt2-large\", max_length=5, temperature=1.0)\n",
    "    },\n",
    "    \n",
    "    prompt_header_llm_concept    = \"In 2 words guess, what task is the model doing:\\n\",\n",
    "    prompt_content_llm_concept   = \"{x_test} -> {y_test}\\n\",\n",
    "    prompt_tail_llm_concept      = \"What is this task?\",\n",
    "    \n",
    "    prompt_header_llm_train    = \"You are a classificator\\n\",\n",
    "    prompt_content_llm_train   = \"{x_train} -> {y_train}\\n\",\n",
    "    prompt_tail_llm_train      = \"Learn based on this.\",\n",
    "    \n",
    "    prompt_llm_simulation= \"{x_test}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd4d0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.concat([model_statistics, model_statistics_tmp], ignore_index=True)\n",
    "prediction_statistics = pd.concat([prediction_statistics, prediction_statistics_tmp], ignore_index=True)\n",
    "data_statistics = pd.concat([data_statistics, data_statistics_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d9fa6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb9b0ed190543c7a863f224c4640d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sebastian\\.cache\\huggingface\\hub\\models--EleutherAI--gpt-neo-125M. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e164b6ba914e2f9ede2f92df800cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8c13e10dbb4c80b292c973fa499c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86d4a222a754c4e9e51661f7fa66eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a45f9ab12f547e7839d702a46c78bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d95a268ba14699a25eaf7c24bad62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cda84461f14721b36a201b31e1d0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc54fdf2e184229ae481f39757a0858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict HF\n",
      "[{'label': 'POSITIVE', 'score': 0.6439165472984314}]\n",
      "predict HF\n",
      "[{'label': 'NEGATIVE', 'score': 0.99978107213974}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict HF\n",
      "[{'label': 'POSITIVE', 'score': 0.9998670816421509}]\n",
      "predict HF\n",
      "[{'label': 'NEGATIVE', 'score': 0.9997370839118958}]\n",
      "Running experiment for LLM: gpt-neo-125M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting concept:\n",
      "Prompt: In 2 words guess, what task is the model doing:\n",
      "I wouldn't recommend this to anyone. -> NEGATIVE\n",
      "It was not an okay film, boring. -> NEGATIVE\n",
      "What a masterpiece! Truly a work of art. -> POSITIVE\n",
      "It bored me to tears, very dull. -> NEGATIVE\n",
      "What is this task?\n",
      "Output: [{'generated_text': \"In 2 words guess, what task is the model doing:\\nI wouldn't recommend this to anyone. -> NEGATIVE\\nIt was not an okay film, boring. -> NEGATIVE\\nWhat a masterpiece! Truly a work of art. -> POSITIVE\\nIt bored me to tears, very dull. -> NEGATIVE\\nWhat is this task?\\n\\nA:\\n\"}]\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: I wouldn't recommend this to anyone.\n",
      "Output: [{'generated_text': \"I wouldn't recommend this to anyone.\\n\\nA:\\n\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: It was not an okay film, boring.\n",
      "Output: [{'generated_text': 'It was not an okay film, boring. It was a good film'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: What a masterpiece! Truly a work of art.\n",
      "Output: [{'generated_text': 'What a masterpiece! Truly a work of art.\\n\\nI’'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: It bored me to tears, very dull.\n",
      "Output: [{'generated_text': 'It bored me to tears, very dull. I was so happy to'}]\n",
      "Running experiment for LLM: gpt2-345M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting concept:\n",
      "Prompt: In 2 words guess, what task is the model doing:\n",
      "I wouldn't recommend this to anyone. -> NEGATIVE\n",
      "It was not an okay film, boring. -> NEGATIVE\n",
      "What a masterpiece! Truly a work of art. -> POSITIVE\n",
      "It bored me to tears, very dull. -> NEGATIVE\n",
      "What is this task?\n",
      "Output: [{'generated_text': \"In 2 words guess, what task is the model doing:\\nI wouldn't recommend this to anyone. -> NEGATIVE\\nIt was not an okay film, boring. -> NEGATIVE\\nWhat a masterpiece! Truly a work of art. -> POSITIVE\\nIt bored me to tears, very dull. -> NEGATIVE\\nWhat is this task? -> NEGATIVE\\n\"}]\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: I wouldn't recommend this to anyone.\n",
      "Output: [{'generated_text': \"I wouldn't recommend this to anyone. I think it would be\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: It was not an okay film, boring.\n",
      "Output: [{'generated_text': 'It was not an okay film, boring. We thought that the next'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting sentiment:\n",
      "Prompt: What a masterpiece! Truly a work of art.\n",
      "Output: [{'generated_text': 'What a masterpiece! Truly a work of art.'}]\n",
      "Predicting sentiment:\n",
      "Prompt: It bored me to tears, very dull.\n",
      "Output: [{'generated_text': 'It bored me to tears, very dull. The whole game is kind'}]\n"
     ]
    }
   ],
   "source": [
    "model_statistics_tmp, prediction_statistics_tmp, data_statistics_tmp = experiment.run(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    dataset_name='test_dataset',\n",
    "    concept=\"sentiment analysis\",\n",
    "    concept_keywords=[\"sentiment\", \"emotion\"],\n",
    "    \n",
    "    classifier_name=\"distilbert-sst2_second\",\n",
    "    classifier=HuggingFaceModel(\"distilbert-base-uncased-finetuned-sst-2-english\"),\n",
    "    \n",
    "    llm_models={\n",
    "        \"gpt-neo-125M\": LLM(\"EleutherAI/gpt-neo-125M\", max_length=5, temperature=1.0),\n",
    "        \"gpt2-345M\": LLM(\"gpt2-medium\", max_length=5, temperature=1.0)\n",
    "    },\n",
    "    \n",
    "    prompt_header_llm_concept    = \"In 2 words guess, what task is the model doing:\\n\",\n",
    "    prompt_content_llm_concept   = \"{x_test} -> {y_test}\\n\",\n",
    "    prompt_tail_llm_concept      = \"What is this task?\",\n",
    "    \n",
    "    prompt_header_llm_train    = \"You are a classificator\\n\",\n",
    "    prompt_content_llm_train   = \"{x_train} -> {y_train}\\n\",\n",
    "    prompt_tail_llm_train      = \"Learn based on this.\",\n",
    "    \n",
    "    prompt_llm_simulation= \"{x_test}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b29ff9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.concat([model_statistics, model_statistics_tmp], ignore_index=True)\n",
    "prediction_statistics = pd.concat([prediction_statistics, prediction_statistics_tmp], ignore_index=True)\n",
    "data_statistics = pd.concat([data_statistics, data_statistics_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb8d72035ef92a",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a45b2f9c0ffa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>llm</th>\n",
       "      <th>classifier_accuracy</th>\n",
       "      <th>llm_concept_accuracy</th>\n",
       "      <th>llm_simulation_accuracy</th>\n",
       "      <th>prompt_header_llm_concept</th>\n",
       "      <th>prompt_content_llm_concept</th>\n",
       "      <th>prompt_tail_llm_concept</th>\n",
       "      <th>prompt_header_llm_train</th>\n",
       "      <th>prompt_content_llm_train</th>\n",
       "      <th>prompt_tail_llm_train</th>\n",
       "      <th>prompt_llm_simulation</th>\n",
       "      <th>llm_predicted_concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Sentimeng guessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Somethin different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-774M</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Sentimeng guessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt-neo-125M</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Sentimeng guessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Sentimeng guessing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id  dataset_name              classifier           llm  \\\n",
       "0       1  test_dataset         distilbert-sst2     gpt2-124M   \n",
       "1       1  test_dataset         distilbert-sst2     gpt2-345M   \n",
       "2       1  test_dataset         distilbert-sst2     gpt2-774M   \n",
       "3       2  test_dataset  distilbert-sst2_second  gpt-neo-125M   \n",
       "4       2  test_dataset  distilbert-sst2_second     gpt2-345M   \n",
       "\n",
       "   classifier_accuracy  llm_concept_accuracy  llm_simulation_accuracy  \\\n",
       "0                 0.75                   0.0                     0.25   \n",
       "1                 0.75                   0.0                     0.50   \n",
       "2                 0.75                   0.0                     0.75   \n",
       "3                 0.75                   0.0                     0.25   \n",
       "4                 0.75                   0.0                     0.00   \n",
       "\n",
       "                           prompt_header_llm_concept  \\\n",
       "0  In 2 words guess, what task is the model doing:\\n   \n",
       "1  In 2 words guess, what task is the model doing:\\n   \n",
       "2  In 2 words guess, what task is the model doing:\\n   \n",
       "3  In 2 words guess, what task is the model doing:\\n   \n",
       "4  In 2 words guess, what task is the model doing:\\n   \n",
       "\n",
       "  prompt_content_llm_concept prompt_tail_llm_concept  \\\n",
       "0     {x_test} -> {y_test}\\n      What is this task?   \n",
       "1     {x_test} -> {y_test}\\n      What is this task?   \n",
       "2     {x_test} -> {y_test}\\n      What is this task?   \n",
       "3     {x_test} -> {y_test}\\n      What is this task?   \n",
       "4     {x_test} -> {y_test}\\n      What is this task?   \n",
       "\n",
       "     prompt_header_llm_train  prompt_content_llm_train prompt_tail_llm_train  \\\n",
       "0  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "1  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "2  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "3  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "4  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "\n",
       "  prompt_llm_simulation llm_predicted_concept  \n",
       "0              {x_test}    Sentimeng guessing  \n",
       "1              {x_test}    Somethin different  \n",
       "2              {x_test}    Sentimeng guessing  \n",
       "3              {x_test}    Sentimeng guessing  \n",
       "4              {x_test}    Sentimeng guessing  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61c30b2fd30583d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>llm_name</th>\n",
       "      <th>x_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>classifier_predicted_label</th>\n",
       "      <th>llm_simulation_predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>I wouldn't recommend this to anyone.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>It was not an okay film, boring.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>What a masterpiece! Truly a work of art.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>It bored me to tears, very dull.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>I wouldn't recommend this to anyone.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>It was not an okay film, boring.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>What a masterpiece! Truly a work of art.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>It bored me to tears, very dull.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-774M</td>\n",
       "      <td>I wouldn't recommend this to anyone.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-774M</td>\n",
       "      <td>It was not an okay film, boring.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-774M</td>\n",
       "      <td>What a masterpiece! Truly a work of art.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-774M</td>\n",
       "      <td>It bored me to tears, very dull.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt-neo-125M</td>\n",
       "      <td>I wouldn't recommend this to anyone.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt-neo-125M</td>\n",
       "      <td>It was not an okay film, boring.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt-neo-125M</td>\n",
       "      <td>What a masterpiece! Truly a work of art.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt-neo-125M</td>\n",
       "      <td>It bored me to tears, very dull.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>I wouldn't recommend this to anyone.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>It was not an okay film, boring.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>What a masterpiece! Truly a work of art.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>It bored me to tears, very dull.</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run_id  dataset_name         classifier_name      llm_name  \\\n",
       "0        1  test_dataset         distilbert-sst2     gpt2-124M   \n",
       "1        1  test_dataset         distilbert-sst2     gpt2-124M   \n",
       "2        1  test_dataset         distilbert-sst2     gpt2-124M   \n",
       "3        1  test_dataset         distilbert-sst2     gpt2-124M   \n",
       "4        1  test_dataset         distilbert-sst2     gpt2-345M   \n",
       "5        1  test_dataset         distilbert-sst2     gpt2-345M   \n",
       "6        1  test_dataset         distilbert-sst2     gpt2-345M   \n",
       "7        1  test_dataset         distilbert-sst2     gpt2-345M   \n",
       "8        1  test_dataset         distilbert-sst2     gpt2-774M   \n",
       "9        1  test_dataset         distilbert-sst2     gpt2-774M   \n",
       "10       1  test_dataset         distilbert-sst2     gpt2-774M   \n",
       "11       1  test_dataset         distilbert-sst2     gpt2-774M   \n",
       "12       2  test_dataset  distilbert-sst2_second  gpt-neo-125M   \n",
       "13       2  test_dataset  distilbert-sst2_second  gpt-neo-125M   \n",
       "14       2  test_dataset  distilbert-sst2_second  gpt-neo-125M   \n",
       "15       2  test_dataset  distilbert-sst2_second  gpt-neo-125M   \n",
       "16       2  test_dataset  distilbert-sst2_second     gpt2-345M   \n",
       "17       2  test_dataset  distilbert-sst2_second     gpt2-345M   \n",
       "18       2  test_dataset  distilbert-sst2_second     gpt2-345M   \n",
       "19       2  test_dataset  distilbert-sst2_second     gpt2-345M   \n",
       "\n",
       "                                      x_test    y_test  \\\n",
       "0       I wouldn't recommend this to anyone.  NEGATIVE   \n",
       "1           It was not an okay film, boring.  NEGATIVE   \n",
       "2   What a masterpiece! Truly a work of art.  POSITIVE   \n",
       "3           It bored me to tears, very dull.  NEGATIVE   \n",
       "4       I wouldn't recommend this to anyone.  NEGATIVE   \n",
       "5           It was not an okay film, boring.  NEGATIVE   \n",
       "6   What a masterpiece! Truly a work of art.  POSITIVE   \n",
       "7           It bored me to tears, very dull.  NEGATIVE   \n",
       "8       I wouldn't recommend this to anyone.  NEGATIVE   \n",
       "9           It was not an okay film, boring.  NEGATIVE   \n",
       "10  What a masterpiece! Truly a work of art.  POSITIVE   \n",
       "11          It bored me to tears, very dull.  NEGATIVE   \n",
       "12      I wouldn't recommend this to anyone.  NEGATIVE   \n",
       "13          It was not an okay film, boring.  NEGATIVE   \n",
       "14  What a masterpiece! Truly a work of art.  POSITIVE   \n",
       "15          It bored me to tears, very dull.  NEGATIVE   \n",
       "16      I wouldn't recommend this to anyone.  NEGATIVE   \n",
       "17          It was not an okay film, boring.  NEGATIVE   \n",
       "18  What a masterpiece! Truly a work of art.  POSITIVE   \n",
       "19          It bored me to tears, very dull.  NEGATIVE   \n",
       "\n",
       "   classifier_predicted_label llm_simulation_predicted_label  \n",
       "0                    POSITIVE                       NEGATIVE  \n",
       "1                    NEGATIVE                       POSITIVE  \n",
       "2                    POSITIVE                       NEGATIVE  \n",
       "3                    NEGATIVE                       NEGATIVE  \n",
       "4                    POSITIVE                       POSITIVE  \n",
       "5                    NEGATIVE                       NEGATIVE  \n",
       "6                    POSITIVE                       NEGATIVE  \n",
       "7                    NEGATIVE                       POSITIVE  \n",
       "8                    POSITIVE                       NEGATIVE  \n",
       "9                    NEGATIVE                       NEGATIVE  \n",
       "10                   POSITIVE                       POSITIVE  \n",
       "11                   NEGATIVE                       NEGATIVE  \n",
       "12                   POSITIVE                       NEGATIVE  \n",
       "13                   NEGATIVE                       POSITIVE  \n",
       "14                   POSITIVE                       NEGATIVE  \n",
       "15                   NEGATIVE                       NEGATIVE  \n",
       "16                   POSITIVE                       NEGATIVE  \n",
       "17                   NEGATIVE                       POSITIVE  \n",
       "18                   POSITIVE                       NEGATIVE  \n",
       "19                   NEGATIVE                       POSITIVE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d99a12878273ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>llm_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>label_counts</th>\n",
       "      <th>label_proportions</th>\n",
       "      <th>avg_text_length</th>\n",
       "      <th>avg_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'POSITIVE': 2, 'NEGATIVE': 2}</td>\n",
       "      <td>{'POSITIVE': 0.5, 'NEGATIVE': 0.5}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'NEGATIVE': 3, 'POSITIVE': 1}</td>\n",
       "      <td>{'NEGATIVE': 0.75, 'POSITIVE': 0.25}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'POSITIVE': 2, 'NEGATIVE': 2}</td>\n",
       "      <td>{'POSITIVE': 0.5, 'NEGATIVE': 0.5}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'NEGATIVE': 3, 'POSITIVE': 1}</td>\n",
       "      <td>{'NEGATIVE': 0.75, 'POSITIVE': 0.25}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-774M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'POSITIVE': 2, 'NEGATIVE': 2}</td>\n",
       "      <td>{'POSITIVE': 0.5, 'NEGATIVE': 0.5}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2</td>\n",
       "      <td>gpt2-774M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'NEGATIVE': 3, 'POSITIVE': 1}</td>\n",
       "      <td>{'NEGATIVE': 0.75, 'POSITIVE': 0.25}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt-neo-125M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'POSITIVE': 2, 'NEGATIVE': 2}</td>\n",
       "      <td>{'POSITIVE': 0.5, 'NEGATIVE': 0.5}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt-neo-125M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'NEGATIVE': 3, 'POSITIVE': 1}</td>\n",
       "      <td>{'NEGATIVE': 0.75, 'POSITIVE': 0.25}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'POSITIVE': 2, 'NEGATIVE': 2}</td>\n",
       "      <td>{'POSITIVE': 0.5, 'NEGATIVE': 0.5}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>test_dataset</td>\n",
       "      <td>distilbert-sst2_second</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>{'NEGATIVE': 3, 'POSITIVE': 1}</td>\n",
       "      <td>{'NEGATIVE': 0.75, 'POSITIVE': 0.25}</td>\n",
       "      <td>47.2</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id  dataset_name         classifier_name      llm_name partition  \\\n",
       "0       1  test_dataset         distilbert-sst2     gpt2-124M     train   \n",
       "1       1  test_dataset         distilbert-sst2     gpt2-124M     train   \n",
       "2       1  test_dataset         distilbert-sst2     gpt2-345M     train   \n",
       "3       1  test_dataset         distilbert-sst2     gpt2-345M     train   \n",
       "4       1  test_dataset         distilbert-sst2     gpt2-774M     train   \n",
       "5       1  test_dataset         distilbert-sst2     gpt2-774M     train   \n",
       "6       2  test_dataset  distilbert-sst2_second  gpt-neo-125M     train   \n",
       "7       2  test_dataset  distilbert-sst2_second  gpt-neo-125M     train   \n",
       "8       2  test_dataset  distilbert-sst2_second     gpt2-345M     train   \n",
       "9       2  test_dataset  distilbert-sst2_second     gpt2-345M     train   \n",
       "\n",
       "   num_samples                    label_counts  \\\n",
       "0            4  {'POSITIVE': 2, 'NEGATIVE': 2}   \n",
       "1            4  {'NEGATIVE': 3, 'POSITIVE': 1}   \n",
       "2            4  {'POSITIVE': 2, 'NEGATIVE': 2}   \n",
       "3            4  {'NEGATIVE': 3, 'POSITIVE': 1}   \n",
       "4            4  {'POSITIVE': 2, 'NEGATIVE': 2}   \n",
       "5            4  {'NEGATIVE': 3, 'POSITIVE': 1}   \n",
       "6            4  {'POSITIVE': 2, 'NEGATIVE': 2}   \n",
       "7            4  {'NEGATIVE': 3, 'POSITIVE': 1}   \n",
       "8            4  {'POSITIVE': 2, 'NEGATIVE': 2}   \n",
       "9            4  {'NEGATIVE': 3, 'POSITIVE': 1}   \n",
       "\n",
       "                      label_proportions  avg_text_length  avg_word_count  \n",
       "0    {'POSITIVE': 0.5, 'NEGATIVE': 0.5}             47.2             7.8  \n",
       "1  {'NEGATIVE': 0.75, 'POSITIVE': 0.25}             47.2             7.8  \n",
       "2    {'POSITIVE': 0.5, 'NEGATIVE': 0.5}             47.2             7.8  \n",
       "3  {'NEGATIVE': 0.75, 'POSITIVE': 0.25}             47.2             7.8  \n",
       "4    {'POSITIVE': 0.5, 'NEGATIVE': 0.5}             47.2             7.8  \n",
       "5  {'NEGATIVE': 0.75, 'POSITIVE': 0.25}             47.2             7.8  \n",
       "6    {'POSITIVE': 0.5, 'NEGATIVE': 0.5}             47.2             7.8  \n",
       "7  {'NEGATIVE': 0.75, 'POSITIVE': 0.25}             47.2             7.8  \n",
       "8    {'POSITIVE': 0.5, 'NEGATIVE': 0.5}             47.2             7.8  \n",
       "9  {'NEGATIVE': 0.75, 'POSITIVE': 0.25}             47.2             7.8  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd976ec390c1bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
