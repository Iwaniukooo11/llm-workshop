{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d447d5285c5e124",
   "metadata": {},
   "source": [
    "# Experiment testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7682c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:43:50.017984Z",
     "start_time": "2025-05-29T17:43:49.979871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\\intermediate\n",
      "C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\\intermediate\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad18c774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:44:02.615785Z",
     "start_time": "2025-05-29T17:44:02.561232Z"
    }
   },
   "outputs": [],
   "source": [
    "from llm_size_experiment import LLMSizeExperiment\n",
    "from core.base_model import BaseModel\n",
    "from tmp.custom_model import EmotionBERT, EmotionClassifier\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Union\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07523033beea36d",
   "metadata": {},
   "source": [
    "## Temporary, for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209e4bfd4fc245d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuggingFaceModel(BaseModel):\n",
    "    def __init__(self, model_name: str = \"distilbert-base-uncased\"):\n",
    "        self.model = pipeline(\"text-classification\", model=model_name)\n",
    "        tok_r = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "        mdl_r = AutoModelForSequenceClassification.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "        self.model = pipeline(\"text-classification\", model=mdl_r, tokenizer=tok_r, device=0, batch_size=32, top_k=None)\n",
    "    def predict(self, input_text: str) -> str:\n",
    "        pred = self.model(input_text)[0][0]\n",
    "        converted = { pred['label']: pred['score'] }\n",
    "        return converted\n",
    "    def train(self, train_loader: DataLoader) -> None:\n",
    "        pass\n",
    "\n",
    "class LLM(BaseModel):\n",
    "    def __init__(self, model_name: str, device: Union[int, str] = 'cpu', **pipeline_kwargs):\n",
    "        if 'max_length' in pipeline_kwargs:\n",
    "            pipeline_kwargs['max_new_tokens'] = pipeline_kwargs.pop('max_length')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model     = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.model.to('cpu')\n",
    "        self.generator = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device=0 if device != 'cpu' else -1,\n",
    "            **pipeline_kwargs\n",
    "        )\n",
    "    def train(self, train_loader: DataLoader, x_train, y_train, prompt) -> None:\n",
    "        pass\n",
    "    def predict(self, input_text: str) -> str:\n",
    "#         outputs = self.generator(input_text, num_return_sequences=1)\n",
    "#         return outputs[0][\"generated_text\"][len(input_text):].strip()\n",
    "        return 'joy'\n",
    "    def predict_concept(self, input_text: str) -> str:\n",
    "#         outputs = self.generator(input_text, num_return_sequences=1)\n",
    "#         return outputs[0][\"generated_text\"][len(input_text):].strip()\n",
    "        return \"Sentimantal sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb26a3691c860e5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aaec4c5e17a1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [\"I am so happy today!\", \"This is really sad news.\", \"I feel quite angry about this.\",\n",
    "        \"Feeling joyful and excited.\", \"What a depressing situation.\", \"He was furious with the outcome.\"]\n",
    "y_train = [\"joy\", \"sadness\", \"anger\", \"joy\", \"sadness\", \"anger\"]\n",
    "\n",
    "x_val = [\"This is great!\", \"I am very upset.\"]\n",
    "y_val = [\"joy\", \"anger\"]\n",
    "\n",
    "x_test = [\"This is not great!\", \"I am very upbeat.\"]\n",
    "y_test = [\"sadness\", \"joy\"]\n",
    "\n",
    "dataset_name='go_emotions'\n",
    "concept=concept=\"sentiment analysis\"\n",
    "concept_keywords=concept_keywords=[\"sentiment\", \"emotion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c521c4",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8e0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = LLMSizeExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18fa75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.DataFrame()\n",
    "prediction_statistics = pd.DataFrame()\n",
    "data_statistics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4a867",
   "metadata": {},
   "source": [
    "### EmotionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30ec4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = EmotionClassifier(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a005bff4192a76cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels setup: 3 unique labels found: ['anger', 'joy', 'sadness']\n",
      "Warning: Could not compute ROC AUC. Error: Number of classes in y_true not equal to the number of columns in 'y_score'. Setting ROC AUC to 0.\n",
      "Epoch 1/2\n",
      "  Train Loss: 1.1972\n",
      "  Val Accuracy: 0.5000\n",
      "  Val F1 Macro: 0.3333\n",
      "  Val ROC AUC (Macro OVR): 0.0000\n",
      "  New best model saved with F1 Macro: 0.3333\n",
      "Warning: Could not compute ROC AUC. Error: Number of classes in y_true not equal to the number of columns in 'y_score'. Setting ROC AUC to 0.\n",
      "Epoch 2/2\n",
      "  Train Loss: 1.0288\n",
      "  Val Accuracy: 0.5000\n",
      "  Val F1 Macro: 0.3333\n",
      "  Val ROC AUC (Macro OVR): 0.0000\n",
      "  New best model saved with F1 Macro: 0.3333\n",
      "Training finished. Loading best model state.\n",
      "Running experiment for LLM: gpt2-124M\n",
      "Running experiment for LLM: gpt2-345M\n"
     ]
    }
   ],
   "source": [
    "model_statistics_tmp, prediction_statistics_tmp, data_statistics_tmp = experiment.run(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    dataset_name=dataset_name,\n",
    "    concept=concept,\n",
    "    concept_keywords=concept_keywords,\n",
    "    \n",
    "    classifier_name=\"EmotionClassifier\",\n",
    "    classifier=classifier,\n",
    "    train_classifier=True,\n",
    "    classifier_train_arguments = {\"epochs\": 2, \"batch_size\": 2},\n",
    "    \n",
    "    llm_models={\n",
    "        \"gpt2-124M\": LLM(\"gpt2\", max_length=5, temperature=1.0),\n",
    "        \"gpt2-345M\": LLM(\"gpt2-medium\", max_length=5, temperature=1.0)\n",
    "    },\n",
    "    \n",
    "    prompt_header_llm_concept    = \"In 2 words guess, what task is the model doing:\\n\",\n",
    "    prompt_content_llm_concept   = \"{x_test} -> {y_test}\\n\",\n",
    "    prompt_tail_llm_concept      = \"What is this task?\",\n",
    "    \n",
    "    prompt_header_llm_train    = \"You are a classificator\\n\",\n",
    "    prompt_content_llm_train   = \"{x_train} -> {y_train}\\n\",\n",
    "    prompt_tail_llm_train      = \"Learn based on this.\",\n",
    "    \n",
    "    prompt_llm_simulation= \"{x_test}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8929c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.concat([model_statistics, model_statistics_tmp], ignore_index=True)\n",
    "prediction_statistics = pd.concat([prediction_statistics, prediction_statistics_tmp], ignore_index=True)\n",
    "data_statistics = pd.concat([data_statistics, data_statistics_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28a13b",
   "metadata": {},
   "source": [
    "### roberta-base-go_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6af839c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sebastian\\anaconda3\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "classifier=HuggingFaceModel(model_name=\"SamLowe/roberta-base-go_emotions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0deeee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for LLM: gpt2-124M\n",
      "Running experiment for LLM: gpt2-345M\n"
     ]
    }
   ],
   "source": [
    "model_statistics_tmp, prediction_statistics_tmp, data_statistics_tmp = experiment.run(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    dataset_name=dataset_name,\n",
    "    concept=concept,\n",
    "    concept_keywords=concept_keywords,\n",
    "    \n",
    "    classifier_name=\"roberta-base-go_emotions\",\n",
    "    classifier=classifier,\n",
    "    train_classifier=False,\n",
    "    classifier_train_arguments = {},\n",
    "    \n",
    "    llm_models={\n",
    "        \"gpt2-124M\": LLM(\"gpt2\", max_length=5, temperature=1.0),\n",
    "        \"gpt2-345M\": LLM(\"gpt2-medium\", max_length=5, temperature=1.0)\n",
    "    },\n",
    "    \n",
    "    prompt_header_llm_concept    = \"In 2 words guess, what task is the model doing:\\n\",\n",
    "    prompt_content_llm_concept   = \"{x_test} -> {y_test}\\n\",\n",
    "    prompt_tail_llm_concept      = \"What is this task?\",\n",
    "    \n",
    "    prompt_header_llm_train    = \"You are a classificator\\n\",\n",
    "    prompt_content_llm_train   = \"{x_train} -> {y_train}\\n\",\n",
    "    prompt_tail_llm_train      = \"Learn based on this.\",\n",
    "    \n",
    "    prompt_llm_simulation= \"{x_test}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a7fe11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.concat([model_statistics, model_statistics_tmp], ignore_index=True)\n",
    "prediction_statistics = pd.concat([prediction_statistics, prediction_statistics_tmp], ignore_index=True)\n",
    "data_statistics = pd.concat([data_statistics, data_statistics_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb8d72035ef92a",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a45b2f9c0ffa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>llm</th>\n",
       "      <th>classifier_accuracy</th>\n",
       "      <th>llm_concept_accuracy</th>\n",
       "      <th>llm_simulation_accuracy</th>\n",
       "      <th>llm_direct_prediction_accuracy</th>\n",
       "      <th>prompt_header_llm_concept</th>\n",
       "      <th>prompt_content_llm_concept</th>\n",
       "      <th>prompt_tail_llm_concept</th>\n",
       "      <th>prompt_header_llm_train</th>\n",
       "      <th>prompt_content_llm_train</th>\n",
       "      <th>prompt_tail_llm_train</th>\n",
       "      <th>prompt_llm_simulation</th>\n",
       "      <th>llm_predicted_concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Predicted concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Predicted concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Predicted concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>Predicted concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name                classifier        llm  \\\n",
       "0       1  go_emotions         EmotionClassifier  gpt2-124M   \n",
       "1       1  go_emotions         EmotionClassifier  gpt2-345M   \n",
       "2       2  go_emotions  roberta-base-go_emotions  gpt2-124M   \n",
       "3       2  go_emotions  roberta-base-go_emotions  gpt2-345M   \n",
       "\n",
       "   classifier_accuracy  llm_concept_accuracy  llm_simulation_accuracy  \\\n",
       "0                  0.5                   0.0                      1.0   \n",
       "1                  0.5                   0.0                      1.0   \n",
       "2                  0.5                   0.0                      0.5   \n",
       "3                  0.5                   0.0                      0.5   \n",
       "\n",
       "   llm_direct_prediction_accuracy  \\\n",
       "0                             0.5   \n",
       "1                             0.5   \n",
       "2                             0.5   \n",
       "3                             0.5   \n",
       "\n",
       "                           prompt_header_llm_concept  \\\n",
       "0  In 2 words guess, what task is the model doing:\\n   \n",
       "1  In 2 words guess, what task is the model doing:\\n   \n",
       "2  In 2 words guess, what task is the model doing:\\n   \n",
       "3  In 2 words guess, what task is the model doing:\\n   \n",
       "\n",
       "  prompt_content_llm_concept prompt_tail_llm_concept  \\\n",
       "0     {x_test} -> {y_test}\\n      What is this task?   \n",
       "1     {x_test} -> {y_test}\\n      What is this task?   \n",
       "2     {x_test} -> {y_test}\\n      What is this task?   \n",
       "3     {x_test} -> {y_test}\\n      What is this task?   \n",
       "\n",
       "     prompt_header_llm_train  prompt_content_llm_train prompt_tail_llm_train  \\\n",
       "0  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "1  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "2  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "3  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "\n",
       "  prompt_llm_simulation llm_predicted_concept  \n",
       "0              {x_test}     Predicted concept  \n",
       "1              {x_test}     Predicted concept  \n",
       "2              {x_test}     Predicted concept  \n",
       "3              {x_test}     Predicted concept  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61c30b2fd30583d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>llm_name</th>\n",
       "      <th>x_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>classifier_predicted_label</th>\n",
       "      <th>classifier_predicted_label_confidence</th>\n",
       "      <th>llm_simulation_predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>This is not great!</td>\n",
       "      <td>sadness</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.401358</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>I am very upbeat.</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.444713</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>This is not great!</td>\n",
       "      <td>sadness</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.401358</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>I am very upbeat.</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.444713</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>This is not great!</td>\n",
       "      <td>sadness</td>\n",
       "      <td>disapproval</td>\n",
       "      <td>0.734601</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>gpt2-124M</td>\n",
       "      <td>I am very upbeat.</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.542846</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>This is not great!</td>\n",
       "      <td>sadness</td>\n",
       "      <td>disapproval</td>\n",
       "      <td>0.734601</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>gpt2-345M</td>\n",
       "      <td>I am very upbeat.</td>\n",
       "      <td>joy</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.542846</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name           classifier_name   llm_name  \\\n",
       "0       1  go_emotions         EmotionClassifier  gpt2-124M   \n",
       "1       1  go_emotions         EmotionClassifier  gpt2-124M   \n",
       "2       1  go_emotions         EmotionClassifier  gpt2-345M   \n",
       "3       1  go_emotions         EmotionClassifier  gpt2-345M   \n",
       "4       2  go_emotions  roberta-base-go_emotions  gpt2-124M   \n",
       "5       2  go_emotions  roberta-base-go_emotions  gpt2-124M   \n",
       "6       2  go_emotions  roberta-base-go_emotions  gpt2-345M   \n",
       "7       2  go_emotions  roberta-base-go_emotions  gpt2-345M   \n",
       "\n",
       "               x_test   y_test classifier_predicted_label  \\\n",
       "0  This is not great!  sadness                        joy   \n",
       "1   I am very upbeat.      joy                        joy   \n",
       "2  This is not great!  sadness                        joy   \n",
       "3   I am very upbeat.      joy                        joy   \n",
       "4  This is not great!  sadness                disapproval   \n",
       "5   I am very upbeat.      joy                        joy   \n",
       "6  This is not great!  sadness                disapproval   \n",
       "7   I am very upbeat.      joy                        joy   \n",
       "\n",
       "   classifier_predicted_label_confidence llm_simulation_predicted_label  \n",
       "0                               0.401358                            joy  \n",
       "1                               0.444713                            joy  \n",
       "2                               0.401358                            joy  \n",
       "3                               0.444713                            joy  \n",
       "4                               0.734601                            joy  \n",
       "5                               0.542846                            joy  \n",
       "6                               0.734601                            joy  \n",
       "7                               0.542846                            joy  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d99a12878273ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>label_counts</th>\n",
       "      <th>label_proportions</th>\n",
       "      <th>avg_text_length</th>\n",
       "      <th>avg_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>{'joy': 2, 'sadness': 2, 'anger': 2}</td>\n",
       "      <td>{'joy': 0.33, 'sadness': 0.33, 'anger': 0.33}</td>\n",
       "      <td>26.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>val</td>\n",
       "      <td>2</td>\n",
       "      <td>{'joy': 1, 'anger': 1}</td>\n",
       "      <td>{'joy': 0.5, 'anger': 0.5}</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>EmotionClassifier</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>{'sadness': 1, 'joy': 1}</td>\n",
       "      <td>{'sadness': 0.5, 'joy': 0.5}</td>\n",
       "      <td>17.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>{'joy': 2, 'sadness': 2, 'anger': 2}</td>\n",
       "      <td>{'joy': 0.33, 'sadness': 0.33, 'anger': 0.33}</td>\n",
       "      <td>26.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>val</td>\n",
       "      <td>2</td>\n",
       "      <td>{'joy': 1, 'anger': 1}</td>\n",
       "      <td>{'joy': 0.5, 'anger': 0.5}</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>test</td>\n",
       "      <td>2</td>\n",
       "      <td>{'sadness': 1, 'joy': 1}</td>\n",
       "      <td>{'sadness': 0.5, 'joy': 0.5}</td>\n",
       "      <td>17.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name           classifier_name partition  num_samples  \\\n",
       "0       1  go_emotions         EmotionClassifier     train            6   \n",
       "1       1  go_emotions         EmotionClassifier       val            2   \n",
       "2       1  go_emotions         EmotionClassifier      test            2   \n",
       "3       2  go_emotions  roberta-base-go_emotions     train            6   \n",
       "4       2  go_emotions  roberta-base-go_emotions       val            2   \n",
       "5       2  go_emotions  roberta-base-go_emotions      test            2   \n",
       "\n",
       "                           label_counts  \\\n",
       "0  {'joy': 2, 'sadness': 2, 'anger': 2}   \n",
       "1                {'joy': 1, 'anger': 1}   \n",
       "2              {'sadness': 1, 'joy': 1}   \n",
       "3  {'joy': 2, 'sadness': 2, 'anger': 2}   \n",
       "4                {'joy': 1, 'anger': 1}   \n",
       "5              {'sadness': 1, 'joy': 1}   \n",
       "\n",
       "                               label_proportions  avg_text_length  \\\n",
       "0  {'joy': 0.33, 'sadness': 0.33, 'anger': 0.33}             26.8   \n",
       "1                     {'joy': 0.5, 'anger': 0.5}             15.0   \n",
       "2                   {'sadness': 0.5, 'joy': 0.5}             17.5   \n",
       "3  {'joy': 0.33, 'sadness': 0.33, 'anger': 0.33}             26.8   \n",
       "4                     {'joy': 0.5, 'anger': 0.5}             15.0   \n",
       "5                   {'sadness': 0.5, 'joy': 0.5}             17.5   \n",
       "\n",
       "   avg_word_count  \n",
       "0             5.0  \n",
       "1             3.5  \n",
       "2             4.0  \n",
       "3             5.0  \n",
       "4             3.5  \n",
       "5             4.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2fcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345e7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
