{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d447d5285c5e124",
   "metadata": {},
   "source": [
    "# Experiment example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7682c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:43:50.017984Z",
     "start_time": "2025-05-29T17:43:49.979871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\\intermediate\n",
      "C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\Sebastian\\Desktop\\GitHubRepositories\\llm-workshop\\intermediate\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad18c774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T17:44:02.615785Z",
     "start_time": "2025-05-29T17:44:02.561232Z"
    }
   },
   "outputs": [],
   "source": [
    "from core.base_model import BaseModel\n",
    "from basic.huggingface_model import HuggingFaceModel\n",
    "from basic.llm_model import LLMModel\n",
    "from intermediate.llm_size_experiment import LLMSizeExperiment\n",
    "from tmp.custom_model import EmotionBERT, EmotionClassifier\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Union\n",
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb26a3691c860e5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc4d4a9-122e-4427-b2fa-208863d5153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_simplified_data = load_dataset(\"go_emotions\", \"simplified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6145e3b0-e985-44e7-b14e-ef55dbe379be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tmp/dict.txt\", \"r\") as f:\n",
    "    emotions = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def prepare_df(df, emotions):\n",
    "    df[\"label\"] = df[\"labels\"].apply(lambda x: x[0])\n",
    "    df[\"sentiment\"] = df[\"label\"].apply(lambda idx: emotions[idx])\n",
    "    return df[[\"text\", \"sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fb33db-5371-4f3b-98fb-d3f089851cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentiment\n",
      "0  My favourite food is anything I didn't have to...    neutral\n",
      "1  Now if he does off himself, everyone will thin...    neutral\n",
      "2                     WHY THE FUCK IS BAYLESS ISOING      anger\n",
      "3                        To make her feel threatened       fear\n",
      "4                             Dirty Southern Wankers  annoyance\n"
     ]
    }
   ],
   "source": [
    "train_df = prepare_df(go_emotions_simplified_data[\"train\"].to_pandas(), emotions)\n",
    "val_df = prepare_df(go_emotions_simplified_data[\"validation\"].to_pandas(), emotions)\n",
    "test_df = prepare_df(go_emotions_simplified_data[\"test\"].to_pandas(), emotions)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a877f961-4917-4782-9b3d-260371973228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"My favourite food is anything I didn't have to cook myself.\", 'Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead', 'WHY THE FUCK IS BAYLESS ISOING', 'To make her feel threatened', 'Dirty Southern Wankers']\n",
      "['neutral', 'neutral', 'anger', 'fear', 'annoyance']\n"
     ]
    }
   ],
   "source": [
    "x_train = train_df['text'].tolist()\n",
    "y_train = train_df['sentiment'].tolist()\n",
    "x_val = val_df['text'].tolist()\n",
    "y_val = val_df['sentiment'].tolist()\n",
    "x_test = test_df['text'].tolist()\n",
    "y_test = test_df['sentiment'].tolist()\n",
    "print(x_train[:5])\n",
    "print(y_train[:5])\n",
    "\n",
    "dataset_name='go_emotions'\n",
    "concept=concept=\"sentiment analysis\"\n",
    "concept_keywords=concept_keywords=[\"sentiment\", \"emotion\"]\n",
    "\n",
    "llm_models={\n",
    "        \"opt-125m\": LLMModel(model_name=\"facebook/opt-125m\", use_gpu=False),\n",
    "        \"opt-350m\": LLMModel(model_name=\"facebook/opt-350m\", use_gpu=False),\n",
    "        # \"opt-1.3b\": LLMModel(model_name=\"facebook/opt-1.3b\", use_gpu=False),\n",
    "        # \"opt-2.7b\": LLMModel(model_name=\"facebook/opt-2.7b\", use_gpu=False),\n",
    "    \n",
    "        # \"opt-6.7b\": LLMModel(model_name=\"facebook/opt-6.7b\", use_gpu=False),\n",
    "        # \"opt-13b\": LLMModel(model_name=\"facebook/opt-13b\", use_gpu=False),\n",
    "        # \"opt-30b\": LLMModel(model_name=\"facebook/opt-30b\", use_gpu=False),\n",
    "        # \"opt-66b\": LLMModel(model_name=\"facebook/opt-66b\", use_gpu=False)\n",
    "    }\n",
    "\n",
    "# Temporary for testing\n",
    "x_train = x_train[:50]\n",
    "y_train = y_train[:50]\n",
    "x_val = x_train\n",
    "y_val = y_train\n",
    "x_test = x_train\n",
    "y_test = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c84cbdd-3d09-4da4-af57-2f56fec2d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e = LLMModel(model_name=\"facebook/opt-6.7b\", use_gpu=False)\n",
    "# e.predict('I am very annoyed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c521c4",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee8e0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = LLMSizeExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b18fa75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.DataFrame()\n",
    "prediction_statistics = pd.DataFrame()\n",
    "data_statistics = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4a867",
   "metadata": {},
   "source": [
    "### EmotionClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ec4802",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_classifier = EmotionClassifier(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a005bff4192a76cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels setup: 18 unique labels found: ['admiration', 'amusement', 'anger', 'annoyance', 'caring', 'confusion', 'curiosity', 'desire', 'disapproval', 'embarrassment', 'fear', 'gratitude', 'grief', 'joy', 'neutral', 'optimism', 'sadness', 'surprise']\n",
      "Epoch 1/2g batch 25/25\n",
      "  Train Loss: 2.8435\n",
      "  Val Accuracy: 0.3400\n",
      "  Val F1 Macro: 0.0456\n",
      "  Val ROC AUC (Macro OVR): 0.8927\n",
      "  New best model saved with F1 Macro: 0.0456\n",
      "Epoch 2/2g batch 25/25\n",
      "  Train Loss: 2.3018\n",
      "  Val Accuracy: 0.3800\n",
      "  Val F1 Macro: 0.0754\n",
      "  Val ROC AUC (Macro OVR): 0.9926\n",
      "  New best model saved with F1 Macro: 0.0754\n",
      "Training finished. Loading best model state.\n",
      "Running experiment for LLM: opt-125m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for LLM: opt-350m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "model_statistics_tmp, prediction_statistics_tmp, data_statistics_tmp = experiment.run(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    dataset_name=dataset_name,\n",
    "    concept=concept,\n",
    "    concept_keywords=concept_keywords,\n",
    "    \n",
    "    classifier_name=\"custom_model\",\n",
    "    classifier=custom_classifier,\n",
    "    train_classifier=True,\n",
    "    classifier_train_arguments = {\"epochs\": 2, \"batch_size\": 2},\n",
    "    \n",
    "    llm_models=llm_models,\n",
    "    \n",
    "    prompt_header_llm_concept    = \"In 2 words guess, what task is the model doing:\\n\",\n",
    "    prompt_content_llm_concept   = \"{x_test} -> {y_test}\\n\",\n",
    "    prompt_tail_llm_concept      = \"What is this task?\",\n",
    "    \n",
    "    prompt_header_llm_train    = \"You are a classificator\\n\",\n",
    "    prompt_content_llm_train   = \"{x_train} -> {y_train}\\n\",\n",
    "    prompt_tail_llm_train      = \"Learn based on this.\",\n",
    "    \n",
    "    prompt_llm_simulation= \"{x_test}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8929c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.concat([model_statistics, model_statistics_tmp], ignore_index=True)\n",
    "prediction_statistics = pd.concat([prediction_statistics, prediction_statistics_tmp], ignore_index=True)\n",
    "data_statistics = pd.concat([data_statistics, data_statistics_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28a13b",
   "metadata": {},
   "source": [
    "### roberta-base-go_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe98494e-186c-41a8-8e1b-270a26c76f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "HGF = HuggingFaceModel(model_name=\"SamLowe/roberta-base-go_emotions\", use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0deeee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for LLM: opt-125m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for LLM: opt-350m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "C:\\Users\\Sebastian\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "model_statistics_tmp, prediction_statistics_tmp, data_statistics_tmp = experiment.run(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test,\n",
    "    x_val=x_val,\n",
    "    y_val=y_val,\n",
    "    dataset_name=dataset_name,\n",
    "    concept=concept,\n",
    "    concept_keywords=concept_keywords,\n",
    "    \n",
    "    classifier_name=\"roberta-base-go_emotions\",\n",
    "    classifier=HGF,\n",
    "    train_classifier=False,\n",
    "    classifier_train_arguments = {},\n",
    "    \n",
    "    llm_models=llm_models,\n",
    "    \n",
    "    prompt_header_llm_concept    = \"In 2 words guess, what task is the model doing:\\n\",\n",
    "    prompt_content_llm_concept   = \"{x_test} -> {y_test}\\n\",\n",
    "    prompt_tail_llm_concept      = \"What is this task?\",\n",
    "    \n",
    "    prompt_header_llm_train    = \"You are a classificator\\n\",\n",
    "    prompt_content_llm_train   = \"{x_train} -> {y_train}\\n\",\n",
    "    prompt_tail_llm_train      = \"Learn based on this.\",\n",
    "    \n",
    "    prompt_llm_simulation= \"{x_test}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a7fe11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_statistics = pd.concat([model_statistics, model_statistics_tmp], ignore_index=True)\n",
    "prediction_statistics = pd.concat([prediction_statistics, prediction_statistics_tmp], ignore_index=True)\n",
    "data_statistics = pd.concat([data_statistics, data_statistics_tmp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fb8d72035ef92a",
   "metadata": {},
   "source": [
    "## View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99a45b2f9c0ffa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>llm</th>\n",
       "      <th>classifier_accuracy</th>\n",
       "      <th>classifier_precision</th>\n",
       "      <th>classifier_recall</th>\n",
       "      <th>classifier_f1</th>\n",
       "      <th>classifier_balanced_accuracy</th>\n",
       "      <th>classifier_cohen_kappa</th>\n",
       "      <th>classifier_mcc</th>\n",
       "      <th>llm_concept_accuracy</th>\n",
       "      <th>llm_simulation_accuracy</th>\n",
       "      <th>llm_simulation_precision</th>\n",
       "      <th>llm_simulation_recall</th>\n",
       "      <th>llm_simulation_f1</th>\n",
       "      <th>llm_simulation_balanced_accuracy</th>\n",
       "      <th>llm_simulation_cohen_kappa</th>\n",
       "      <th>llm_simulation_mcc</th>\n",
       "      <th>llm_direct_prediction_accuracy</th>\n",
       "      <th>llm_direct_precision</th>\n",
       "      <th>llm_direct_recall</th>\n",
       "      <th>llm_direct_f1</th>\n",
       "      <th>llm_direct_balanced_accuracy</th>\n",
       "      <th>llm_direct_cohen_kappa</th>\n",
       "      <th>llm_direct_mcc</th>\n",
       "      <th>prompt_header_llm_concept</th>\n",
       "      <th>prompt_content_llm_concept</th>\n",
       "      <th>prompt_tail_llm_concept</th>\n",
       "      <th>prompt_header_llm_train</th>\n",
       "      <th>prompt_content_llm_train</th>\n",
       "      <th>prompt_tail_llm_train</th>\n",
       "      <th>prompt_llm_simulation</th>\n",
       "      <th>llm_predicted_concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>opt-125m</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.130787</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.075356</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.075179</td>\n",
       "      <td>0.196844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>opt-350m</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.130787</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.075356</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.075179</td>\n",
       "      <td>0.196844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>’’’’’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>opt-125m</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.515530</td>\n",
       "      <td>0.528342</td>\n",
       "      <td>0.510698</td>\n",
       "      <td>0.645752</td>\n",
       "      <td>0.695550</td>\n",
       "      <td>0.698837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>3.660024e-03</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>opt-350m</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.515530</td>\n",
       "      <td>0.528342</td>\n",
       "      <td>0.510698</td>\n",
       "      <td>0.645752</td>\n",
       "      <td>0.695550</td>\n",
       "      <td>0.698837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>In 2 words guess, what task is the model doing:\\n</td>\n",
       "      <td>{x_test} -&gt; {y_test}\\n</td>\n",
       "      <td>What is this task?</td>\n",
       "      <td>You are a classificator\\n</td>\n",
       "      <td>{x_train} -&gt; {y_train}\\n</td>\n",
       "      <td>Learn based on this.</td>\n",
       "      <td>{x_test}</td>\n",
       "      <td>’’’’’</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name                classifier       llm  \\\n",
       "0       1  go_emotions              custom_model  opt-125m   \n",
       "1       1  go_emotions              custom_model  opt-350m   \n",
       "2       2  go_emotions  roberta-base-go_emotions  opt-125m   \n",
       "3       2  go_emotions  roberta-base-go_emotions  opt-350m   \n",
       "\n",
       "   classifier_accuracy  classifier_precision  classifier_recall  \\\n",
       "0                 0.38              0.130787           0.085185   \n",
       "1                 0.38              0.130787           0.085185   \n",
       "2                 0.74              0.515530           0.528342   \n",
       "3                 0.74              0.515530           0.528342   \n",
       "\n",
       "   classifier_f1  classifier_balanced_accuracy  classifier_cohen_kappa  \\\n",
       "0       0.075356                      0.085185                0.075179   \n",
       "1       0.075356                      0.085185                0.075179   \n",
       "2       0.510698                      0.645752                0.695550   \n",
       "3       0.510698                      0.645752                0.695550   \n",
       "\n",
       "   classifier_mcc  llm_concept_accuracy  llm_simulation_accuracy  \\\n",
       "0        0.196844                   0.0                     0.00   \n",
       "1        0.196844                   0.0                     0.00   \n",
       "2        0.698837                   0.0                     0.02   \n",
       "3        0.698837                   0.0                     0.00   \n",
       "\n",
       "   llm_simulation_precision  llm_simulation_recall  llm_simulation_f1  \\\n",
       "0                  0.000000               0.000000           0.000000   \n",
       "1                  0.000000               0.000000           0.000000   \n",
       "2                  0.001161               0.047619           0.002268   \n",
       "3                  0.000000               0.000000           0.000000   \n",
       "\n",
       "   llm_simulation_balanced_accuracy  llm_simulation_cohen_kappa  \\\n",
       "0                          0.000000                1.110223e-16   \n",
       "1                          0.000000                0.000000e+00   \n",
       "2                          0.052632                3.660024e-03   \n",
       "3                          0.000000               -2.220446e-16   \n",
       "\n",
       "   llm_simulation_mcc  llm_direct_prediction_accuracy  llm_direct_precision  \\\n",
       "0            0.000000                             0.0                   0.0   \n",
       "1            0.000000                             0.0                   0.0   \n",
       "2            0.007088                             0.0                   0.0   \n",
       "3            0.000000                             0.0                   0.0   \n",
       "\n",
       "   llm_direct_recall  llm_direct_f1  llm_direct_balanced_accuracy  \\\n",
       "0                0.0            0.0                           0.0   \n",
       "1                0.0            0.0                           0.0   \n",
       "2                0.0            0.0                           0.0   \n",
       "3                0.0            0.0                           0.0   \n",
       "\n",
       "   llm_direct_cohen_kappa  llm_direct_mcc  \\\n",
       "0                     0.0             0.0   \n",
       "1                     0.0             0.0   \n",
       "2                     0.0             0.0   \n",
       "3                     0.0             0.0   \n",
       "\n",
       "                           prompt_header_llm_concept  \\\n",
       "0  In 2 words guess, what task is the model doing:\\n   \n",
       "1  In 2 words guess, what task is the model doing:\\n   \n",
       "2  In 2 words guess, what task is the model doing:\\n   \n",
       "3  In 2 words guess, what task is the model doing:\\n   \n",
       "\n",
       "  prompt_content_llm_concept prompt_tail_llm_concept  \\\n",
       "0     {x_test} -> {y_test}\\n      What is this task?   \n",
       "1     {x_test} -> {y_test}\\n      What is this task?   \n",
       "2     {x_test} -> {y_test}\\n      What is this task?   \n",
       "3     {x_test} -> {y_test}\\n      What is this task?   \n",
       "\n",
       "     prompt_header_llm_train  prompt_content_llm_train prompt_tail_llm_train  \\\n",
       "0  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "1  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "2  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "3  You are a classificator\\n  {x_train} -> {y_train}\\n  Learn based on this.   \n",
       "\n",
       "  prompt_llm_simulation llm_predicted_concept  \n",
       "0              {x_test}                    or  \n",
       "1              {x_test}                 ’’’’’  \n",
       "2              {x_test}                    or  \n",
       "3              {x_test}                 ’’’’’  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61c30b2fd30583d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>llm_name</th>\n",
       "      <th>x_test</th>\n",
       "      <th>y_test</th>\n",
       "      <th>classifier_predicted_label</th>\n",
       "      <th>classifier_predicted_label_confidence</th>\n",
       "      <th>llm_simulation_predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>opt-125m</td>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.666657</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>opt-125m</td>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.548849</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>opt-125m</td>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>anger</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.344517</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>opt-125m</td>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.192742</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>opt-125m</td>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>annoyance</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.205182</td>\n",
       "      <td>i,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name classifier_name  llm_name  \\\n",
       "0       1  go_emotions    custom_model  opt-125m   \n",
       "1       1  go_emotions    custom_model  opt-125m   \n",
       "2       1  go_emotions    custom_model  opt-125m   \n",
       "3       1  go_emotions    custom_model  opt-125m   \n",
       "4       1  go_emotions    custom_model  opt-125m   \n",
       "\n",
       "                                              x_test     y_test  \\\n",
       "0  My favourite food is anything I didn't have to...    neutral   \n",
       "1  Now if he does off himself, everyone will thin...    neutral   \n",
       "2                     WHY THE FUCK IS BAYLESS ISOING      anger   \n",
       "3                        To make her feel threatened       fear   \n",
       "4                             Dirty Southern Wankers  annoyance   \n",
       "\n",
       "  classifier_predicted_label  classifier_predicted_label_confidence  \\\n",
       "0                    neutral                               0.666657   \n",
       "1                    neutral                               0.548849   \n",
       "2                    neutral                               0.344517   \n",
       "3                    neutral                               0.192742   \n",
       "4                    neutral                               0.205182   \n",
       "\n",
       "  llm_simulation_predicted_label  \n",
       "0                           love  \n",
       "1                           love  \n",
       "2                           love  \n",
       "3                           love  \n",
       "4                             i,  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d99a12878273ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>partition</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>label_counts</th>\n",
       "      <th>label_proportions</th>\n",
       "      <th>avg_text_length</th>\n",
       "      <th>avg_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>train</td>\n",
       "      <td>50</td>\n",
       "      <td>{'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...</td>\n",
       "      <td>{'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...</td>\n",
       "      <td>61.7</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>val</td>\n",
       "      <td>50</td>\n",
       "      <td>{'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...</td>\n",
       "      <td>{'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...</td>\n",
       "      <td>61.7</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>custom_model</td>\n",
       "      <td>test</td>\n",
       "      <td>50</td>\n",
       "      <td>{'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...</td>\n",
       "      <td>{'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...</td>\n",
       "      <td>61.7</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>train</td>\n",
       "      <td>50</td>\n",
       "      <td>{'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...</td>\n",
       "      <td>{'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...</td>\n",
       "      <td>61.7</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>go_emotions</td>\n",
       "      <td>roberta-base-go_emotions</td>\n",
       "      <td>val</td>\n",
       "      <td>50</td>\n",
       "      <td>{'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...</td>\n",
       "      <td>{'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...</td>\n",
       "      <td>61.7</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run_id dataset_name           classifier_name partition  num_samples  \\\n",
       "0       1  go_emotions              custom_model     train           50   \n",
       "1       1  go_emotions              custom_model       val           50   \n",
       "2       1  go_emotions              custom_model      test           50   \n",
       "3       2  go_emotions  roberta-base-go_emotions     train           50   \n",
       "4       2  go_emotions  roberta-base-go_emotions       val           50   \n",
       "\n",
       "                                        label_counts  \\\n",
       "0  {'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...   \n",
       "1  {'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...   \n",
       "2  {'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...   \n",
       "3  {'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...   \n",
       "4  {'neutral': 17, 'anger': 5, 'fear': 1, 'annoya...   \n",
       "\n",
       "                                   label_proportions  avg_text_length  \\\n",
       "0  {'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...             61.7   \n",
       "1  {'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...             61.7   \n",
       "2  {'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...             61.7   \n",
       "3  {'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...             61.7   \n",
       "4  {'neutral': 0.34, 'anger': 0.1, 'fear': 0.02, ...             61.7   \n",
       "\n",
       "   avg_word_count  \n",
       "0            11.4  \n",
       "1            11.4  \n",
       "2            11.4  \n",
       "3            11.4  \n",
       "4            11.4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2fcea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345e7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
