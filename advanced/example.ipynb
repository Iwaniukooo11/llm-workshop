{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc28ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dd6dcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/iwaniukooo/Documents/Projects/wb2-llm/llm-workshop/advanced/..\n",
      "Adding /home/iwaniukooo/Documents/Projects/wb2-llm/llm-workshop/advanced/.. to sys.path\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('basic'):\n",
    "    project_root = os.path.dirname(current_dir)\n",
    "else:\n",
    "    project_root = os.path.join(current_dir, '..')\n",
    "print(project_root)\n",
    "if project_root not in sys.path:\n",
    "    print(f\"Adding {project_root} to sys.path\")\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10c98cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iwaniukooo/Documents/Projects/wb2-llm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from basic.llm_model import LLMModel\n",
    "# from llm_model import LLMModel\n",
    "from datasets import load_dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec424828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admiration',\n",
       " 'amusement',\n",
       " 'anger',\n",
       " 'annoyance',\n",
       " 'approval',\n",
       " 'caring',\n",
       " 'confusion',\n",
       " 'curiosity',\n",
       " 'desire',\n",
       " 'disappointment',\n",
       " 'disapproval',\n",
       " 'disgust',\n",
       " 'embarrassment',\n",
       " 'excitement',\n",
       " 'fear',\n",
       " 'gratitude',\n",
       " 'grief',\n",
       " 'joy',\n",
       " 'love',\n",
       " 'nervousness',\n",
       " 'optimism',\n",
       " 'pride',\n",
       " 'realization',\n",
       " 'relief',\n",
       " 'remorse',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"go_emotions\", \"simplified\")\n",
    "with open(\"dict.txt\", \"r\") as f:\n",
    "    emotion_dict = [line.strip() for line in f]\n",
    "\n",
    "emotion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf2f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_subset = dataset['train'].shuffle(seed=43).select(range(4500))  \n",
    "\n",
    "all_texts = data_subset['text']\n",
    "all_labels = data_subset['labels'] \n",
    "all_labels = [label[0] for label in all_labels]  \n",
    "all_labels = [emotion_dict[int(label)] for label in all_labels]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=25\n",
    "n_plus=n+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3bc6f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts = all_texts[:n], all_texts[n:n_plus]\n",
    "train_labels, val_labels = all_labels[:n], all_labels[n:n_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21fe78bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Hugging Face client for model: meta-llama/Llama-3.3-70B-Instruct\n",
      "Client initialized successfully\n"
     ]
    }
   ],
   "source": [
    "llm = LLMModel()\n",
    "# llm = LLMModel(model_name=\"facebook/opt-350m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a2a6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept prediction prompt:\n",
      "In 2 words guess, what task is the model doing, the format is x_test -> y_test:\n",
      "Yeah for sure, they're too smart to go to class anyway, they've got time. -> admiration\n",
      "Me too. I have so much shit and I can’t imagine taking any of it into my car and piling it that high. Wtf? -> anger\n",
      "I get it. However that person doesn’t know who you are... -> neutral\n",
      "He's both. An edgy neckbeard skinny fat, but he is undeniably funny.  -> amusement\n",
      "Keep in mind with these verses you've selected you aren't mentioning how we must he crucified in the flesh with [NAME]. -> neutral\n",
      "What is this task?\n",
      "\n",
      "Predicted concept: Emotion classification\n",
      "Training completed with 5 examples\n"
     ]
    }
   ],
   "source": [
    "llm.train(train_texts,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a15f379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction prompt for 'I tried that. It doesn't work out very well. You become a machine.':\n",
      "You are a classificator\n",
      "Yeah for sure, they're too smart to go to class anyway, they've got time. -> admiration\n",
      "Me too. I have so much shit and I can’t imagine taking any of it into my car and piling it that high. Wtf? -> anger\n",
      "I get it. However that person doesn’t know who you are... -> neutral\n",
      "He's both. An edgy neckbeard skinny fat, but he is undeniably funny.  -> amusement\n",
      "Keep in mind with these verses you've selected you aren't mentioning how we must he crucified in the flesh with [NAME]. -> neutral\n",
      "Learn based on this.\n",
      "\n",
      "Now predict the output for: I tried that. It doesn't work out very well. You become a machine.\n",
      "Output (just plain answer):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['neutral']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(val_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "442aca8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels setup: 28 unique labels found: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'neutral', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise']\n",
      "Tekst: 'i want to cry, depression is coming, life is worth nothing'\n",
      "Przewidywane emocje: {'disappointment': 0.7149401307106018}\n"
     ]
    }
   ],
   "source": [
    "from custom_model import EmotionClassifier\n",
    "from custom_model import EmotionBERT\n",
    "import torch\n",
    "\n",
    "def main():\n",
    "    \n",
    "    classifier = EmotionClassifier(device='cpu')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        with open(\"dict.txt\", \"r\") as f:\n",
    "            emotion_labels = [line.strip() for line in f]\n",
    "        \n",
    "        \n",
    "        classifier._setup_labels(emotion_labels)\n",
    "        \n",
    "        \n",
    "        classifier.model = EmotionBERT(n_classes=len(emotion_labels))\n",
    "        \n",
    "        \n",
    "        classifier.model.load_state_dict(torch.load('best_model_state.pth'))\n",
    "        \n",
    "        \n",
    "        example_text = \"i want to cry, depression is coming, life is worth nothing\"\n",
    "        predicted_labels = classifier.predict(example_text)\n",
    "        \n",
    "        print(f\"Tekst: '{example_text}'\")\n",
    "        print(f\"Przewidywane emocje: {predicted_labels}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Błąd: Nie znaleziono pliku modelu 'best_model_state.pth' lub 'dict.txt'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Wystąpił błąd: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
